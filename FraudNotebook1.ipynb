{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Credit Card Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # Wrapper to save time when running all cells\n",
    "    # Standard Packages\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import markdown\n",
    "    import os\n",
    "\n",
    "    # Viz Packages\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Scipy Stats\n",
    "    import scipy.stats as stats\n",
    "    from scipy.special import logit, expit\n",
    "\n",
    "    # Statsmodel Api\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols\n",
    "\n",
    "    # SKLearn Modules\n",
    "    from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "    from sklearn.feature_selection import RFE\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder, normalize\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, log_loss, confusion_matrix, RocCurveDisplay, plot_roc_curve, classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "    from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
    "    from sklearn.datasets import load_diabetes\n",
    "    from sklearn.model_selection import train_test_split, cross_validate, KFold, cross_val_score\n",
    "    from sklearn import datasets\n",
    "\n",
    "    # Suppress future, deprecation, and SettingWithCopy warnings\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category= FutureWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    # make all columns in a df viewable\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.width = None\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Business Problem\n",
    "\n",
    "We've been hired by **Insert Credit Agency** to create a screener to help protect their clients from potentially fradulent purchases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from Kaggle, Synthetically Generated, Already splitted for us. Synthetically Generated good because data like this usually encrypted/not available to public. No missing values, should be easier to clean and prep for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Fraud Test and Train\n",
    "fraudTrain = pd.read_csv('data/fraudTrain.csv')\n",
    "fraudTest = pd.read_csv('data/fraudTest.csv')\n",
    "# Concatenate them for sake of EDA\n",
    "fraudDF = pd.concat([fraudTrain, fraudTest], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2019-01-01 00:00:18  2703186189652095   \n",
       "1           1   2019-01-01 00:00:44      630423337322   \n",
       "2           2   2019-01-01 00:00:51    38859492057661   \n",
       "3           3   2019-01-01 00:01:16  3534093764340240   \n",
       "4           4   2019-01-01 00:03:06   375534208663984   \n",
       "\n",
       "                             merchant       category     amt      first  \\\n",
       "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
       "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
       "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
       "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
       "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
       "\n",
       "      last gender                        street  ...      lat      long  \\\n",
       "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
       "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
       "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
       "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
       "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job         dob  \\\n",
       "0      3495          Psychologist, counselling  1988-03-09   \n",
       "1       149  Special educational needs teacher  1978-06-21   \n",
       "2      4154        Nature conservation officer  1962-01-19   \n",
       "3      1939                    Patent attorney  1967-01-12   \n",
       "4        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1852394 entries, 0 to 555718\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Unnamed: 0             int64  \n",
      " 1   trans_date_trans_time  object \n",
      " 2   cc_num                 int64  \n",
      " 3   merchant               object \n",
      " 4   category               object \n",
      " 5   amt                    float64\n",
      " 6   first                  object \n",
      " 7   last                   object \n",
      " 8   gender                 object \n",
      " 9   street                 object \n",
      " 10  city                   object \n",
      " 11  state                  object \n",
      " 12  zip                    int64  \n",
      " 13  lat                    float64\n",
      " 14  long                   float64\n",
      " 15  city_pop               int64  \n",
      " 16  job                    object \n",
      " 17  dob                    object \n",
      " 18  trans_num              object \n",
      " 19  unix_time              int64  \n",
      " 20  merch_lat              float64\n",
      " 21  merch_long             float64\n",
      " 22  is_fraud               int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 339.2+ MB\n"
     ]
    }
   ],
   "source": [
    "fraudDF.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We (obviously) have no missing values, since the data is artificially generated. However, their are some things that we need to set up in order to conduct our analysis.\n",
    "1. Since we will be using unix time, as it is much easier to manipulate, we can drop trans_date_trans_time. \n",
    "2. Convert Gender Column into a boolean\n",
    "3. Convert cc_num to a string\n",
    "4. Find best identifier for transaction tracking (Name? Credit Card Number? Address? Some sort of mix?)\n",
    "5. Drop useless columns, such as Unnamed:0 as that obviously does not effect whether or not a purchase is fraudulent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via further analysis (Not included here), it seems that 1 of the people did not make any purchases with a credit card, so we only have 999 unique people in our dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop blatantly useless columns\n",
    "fraudTrain.drop(['Unnamed: 0','trans_date_trans_time'], axis = 1, inplace = True)\n",
    "fraudTest.drop(['Unnamed: 0','trans_date_trans_time'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudDF['full_name'] = fraudDF['first'] + ' ' + fraudDF['last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "989"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudDF['full_name'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not getting every unique person, but maybe we can also concatenate their street, in order to address the 10 people with shared names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudDF['full_name_street'] = fraudDF['full_name'] + ' on ' + fraudDF['street']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudDF['full_name_street'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked! Now that we have a working identifier, we can drop all of the columns used in it (first, last, street), as well as other columns we may have used to identify people such as cc_num, job, and dob.\n",
    "\n",
    "We also will apply the manipulations above to the pre-split dataframes, as we will be using those going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTrain['full_name_street'] = fraudTrain['first'] + ' ' + fraudTrain['last'] + ' on ' + fraudTrain['street']\n",
    "fraudTest['full_name_street'] = fraudTest['first'] + ' ' + fraudTest['last'] + ' on ' + fraudTest['street']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTrain.drop(['first','last','street','cc_num','job','dob'], axis = 1, inplace=True)\n",
    "fraudTest.drop(['first','last','street','cc_num','job','dob'], axis = 1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make our identifier the first column in our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTrain.set_index(\"full_name_street\", inplace=True)\n",
    "fraudTest.set_index(\"full_name_street\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTrain.reset_index(inplace=True)\n",
    "fraudTest.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   full_name_street  1296675 non-null  object \n",
      " 1   merchant          1296675 non-null  object \n",
      " 2   category          1296675 non-null  object \n",
      " 3   amt               1296675 non-null  float64\n",
      " 4   gender            1296675 non-null  object \n",
      " 5   city              1296675 non-null  object \n",
      " 6   state             1296675 non-null  object \n",
      " 7   zip               1296675 non-null  int64  \n",
      " 8   lat               1296675 non-null  float64\n",
      " 9   long              1296675 non-null  float64\n",
      " 10  city_pop          1296675 non-null  int64  \n",
      " 11  trans_num         1296675 non-null  object \n",
      " 12  unix_time         1296675 non-null  int64  \n",
      " 13  merch_lat         1296675 non-null  float64\n",
      " 14  merch_long        1296675 non-null  float64\n",
      " 15  is_fraud          1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(4), object(7)\n",
      "memory usage: 158.3+ MB\n"
     ]
    }
   ],
   "source": [
    "fraudTrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555719 entries, 0 to 555718\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   full_name_street  555719 non-null  object \n",
      " 1   merchant          555719 non-null  object \n",
      " 2   category          555719 non-null  object \n",
      " 3   amt               555719 non-null  float64\n",
      " 4   gender            555719 non-null  object \n",
      " 5   city              555719 non-null  object \n",
      " 6   state             555719 non-null  object \n",
      " 7   zip               555719 non-null  int64  \n",
      " 8   lat               555719 non-null  float64\n",
      " 9   long              555719 non-null  float64\n",
      " 10  city_pop          555719 non-null  int64  \n",
      " 11  trans_num         555719 non-null  object \n",
      " 12  unix_time         555719 non-null  int64  \n",
      " 13  merch_lat         555719 non-null  float64\n",
      " 14  merch_long        555719 non-null  float64\n",
      " 15  is_fraud          555719 non-null  int64  \n",
      "dtypes: float64(5), int64(4), object(7)\n",
      "memory usage: 67.8+ MB\n"
     ]
    }
   ],
   "source": [
    "fraudTest.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the ugly stuff. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Male or Female Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1289169\n",
       "1       7506\n",
       "Name: is_fraud, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudTrain['is_fraud'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Business Problem specifies that we a creating a screener, so we want to catch almost all fraudulent purchases, don't care too much about False-Positives, so we will use Recall as our scoring metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, if we classify every purchase as fradulent, we would get a recall of 1, but that would be an extremely shitty screener. We have to do more work than that. Let's make a baseline logistic regression model, just with the columns we currently have- not taking anything else into account. We would expect this to be a bad model, but it is a good place to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Jennifer Banks on 561 Perry Cove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m y_train \u001b[39m=\u001b[39m fraudTrain[\u001b[39m'\u001b[39m\u001b[39mis_fraud\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m BaselineModel \u001b[39m=\u001b[39m LogisticRegression(random_state \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m, solver \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m BaselineModel\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\cnade\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1196\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[0;32m   1199\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1200\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1201\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[0;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\cnade\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    552\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\cnade\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[1;32m-> 1104\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1105\u001b[0m     X,\n\u001b[0;32m   1106\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1107\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1108\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1109\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1110\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1111\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1112\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1113\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1114\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1115\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1116\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1117\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1118\u001b[0m )\n\u001b[0;32m   1120\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1122\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\cnade\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    875\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    876\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 877\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    879\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    881\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cnade\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cnade\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\core\\_asarray.py:83\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m@set_module\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39masarray\u001b[39m(a, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     16\u001b[0m     \u001b[39m\"\"\"Convert the input to an array.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Users\\cnade\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[1;32mc:\\Users\\cnade\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\core\\_asarray.py:83\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m@set_module\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39masarray\u001b[39m(a, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     16\u001b[0m     \u001b[39m\"\"\"Convert the input to an array.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Jennifer Banks on 561 Perry Cove'"
     ]
    }
   ],
   "source": [
    "X_train = fraudTrain.drop(['is_fraud'], axis = 1)\n",
    "y_train = fraudTrain['is_fraud']\n",
    "\n",
    "BaselineModel = LogisticRegression(random_state = 42, solver = 'sag')\n",
    "BaselineModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Quality???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
